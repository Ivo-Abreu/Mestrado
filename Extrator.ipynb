{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45545c00",
   "metadata": {},
   "source": [
    "# Extrator de estatísticas da detecção\n",
    "Agrupa os dados das iterações por mediana e média para posterior análise. Recebe como entrada os arquivos do caderno Detector.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4040eba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "from timer import timer\n",
    "\n",
    "# Arquivos de entrada\n",
    "tables = ['table1.csv','table2.csv','table3.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8412bc38",
   "metadata": {},
   "source": [
    "Extração dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18db1ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 36/36 [04:50<00:00,  8.06s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 213/213 [29:06<00:00,  8.20s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 306/306 [40:59<00:00,  8.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 1h 16m 36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tic = time()\n",
    "metrics = ['Accuracy','Recall','F1','AUC']\n",
    "resultado = {}\n",
    "resultado['HAI'] = []\n",
    "resultado['Files'] = []\n",
    "resultado['Selector'] = []\n",
    "resultado['N_Samples'] = []\n",
    "resultado['Test_Size'] = []\n",
    "resultado['Contamination'] = []\n",
    "resultado['Classifier_1s'] = []\n",
    "for metric in metrics:\n",
    "    resultado[\"Classifier_2s_\"+metric+\"_Median\"]=[]\n",
    "    resultado[\"Classifier_2s_\"+metric+\"_Mean\"]=[]\n",
    "    resultado[metric+\"_1s_Median\"]=[]\n",
    "    resultado[metric+\"_1s_Mean\"]=[]\n",
    "    resultado[metric+\"_2s_Median\"]=[]\n",
    "    resultado[metric+\"_2s_Mean\"]=[]\n",
    "for a,b,c in product(metrics,[\"Abs\",\"Rel\"],[\"Median\",\"Mean\"]):\n",
    "    resultado['_'.join([a,b,c])]=[]\n",
    "for a in [\"FP\",\"FN\",\"FPR\",\"FNR\"]:\n",
    "    resultado[a+\"_1s_Median\"]=[]\n",
    "    resultado[a+\"_1s_Mean\"]=[]\n",
    "for a,b in product([\"FP\",\"FN\",\"FPR\",\"FNR\"],metrics):\n",
    "    resultado[a+\"_2s_Median_\"+b]=[]\n",
    "    resultado[a+\"_2s_Mean_\"+b]=[]\n",
    "for table in tables:\n",
    "    df = pd.read_csv(table)\n",
    "    aux = df.groupby(['HAI','Files','Selector','N_Samples','Test_Size','Contamination']).count().reset_index()\n",
    "    params = []\n",
    "    for i in range(aux.shape[0]):\n",
    "        params.append((aux.iloc[i,0],\n",
    "                       aux.iloc[i,1],\n",
    "                       aux.iloc[i,2],\n",
    "                       aux.iloc[i,3],\n",
    "                       aux.iloc[i,4],\n",
    "                       aux.iloc[i,5]))\n",
    "    del aux\n",
    "\n",
    "    for param in tqdm(params):\n",
    "        version = param[0]\n",
    "        files = param[1]\n",
    "        fselector = param[2]\n",
    "        n_samples = str(param[3])\n",
    "        test_size = str(param[4])\n",
    "        contamination = str(param[5])\n",
    "        data = df.query(\"HAI == '\"+version+\n",
    "                        \"' and Files == '\"+files+\n",
    "                        \"' and Selector == '\"+fselector+\n",
    "                        \"' and N_Samples == \"+n_samples+\n",
    "                        \" and Test_Size == \"+test_size+\n",
    "                        \" and Contamination == \"+contamination)\n",
    "        for s1clf in data['Classifier_1s'].unique():\n",
    "            resultado['HAI'].append(version)\n",
    "            resultado['Files'].append(files)\n",
    "            resultado['Selector'].append(fselector)\n",
    "            resultado['N_Samples'].append(n_samples)\n",
    "            resultado['Test_Size'].append(test_size)\n",
    "            resultado['Contamination'].append(contamination)\n",
    "            resultado['Classifier_1s'].append(s1clf)\n",
    "            dataux = data.query(\"Classifier_1s == '\"+s1clf+\"' and Classifier_2s == '1step_only'\")\n",
    "            \n",
    "            median_fp_1s = pd.Series(dataux['FP']).median()\n",
    "            resultado['FP_1s_Median'].append(median_fp_1s)\n",
    "            median_fn_1s = pd.Series(dataux['FN']).median()\n",
    "            resultado['FN_1s_Median'].append(median_fn_1s)\n",
    "\n",
    "            resultado['FPR_1s_Median'].append(median_fp_1s/(int(test_size)-int(contamination)))\n",
    "            resultado['FNR_1s_Median'].append(median_fn_1s/int(contamination))\n",
    "\n",
    "            mean_fp_1s = pd.Series(dataux['FP']).mean()\n",
    "            resultado['FP_1s_Mean'].append(mean_fp_1s)\n",
    "            mean_fn_1s = pd.Series(dataux['FN']).mean()\n",
    "            resultado['FN_1s_Mean'].append(mean_fn_1s)\n",
    "\n",
    "            resultado['FPR_1s_Mean'].append(mean_fp_1s/(int(test_size)-int(contamination)))\n",
    "            resultado['FNR_1s_Mean'].append(mean_fn_1s/int(contamination))\n",
    "            for metric in metrics:\n",
    "                aux = {}\n",
    "                diff = 0\n",
    "                last = \"1step_only\"\n",
    "                last_fp = 9999999\n",
    "                median_1s = dataux[metric].median()\n",
    "                resultado[metric+\"_1s_Median\"].append(median_1s)\n",
    "                mean_1s = dataux[metric].mean()\n",
    "                resultado[metric+\"_1s_Mean\"].append(mean_1s)\n",
    "                if median_1s == 0.0:\n",
    "                    for s2clf in data['Classifier_2s'].unique():\n",
    "                        median_2s = data.query(\"Classifier_1s == '\"+s1clf+\"' and Classifier_2s == '\"+s2clf+\"'\")[metric].median()\n",
    "                        median_fp_2s = data.query(\"Classifier_1s == '\"+s1clf+\"' and Classifier_2s == '\"+s2clf+\"'\")['FP'].median()\n",
    "                        if median_2s-median_1s > diff:\n",
    "                            diff = median_2s-median_1s\n",
    "                            last = s2clf\n",
    "                            last_fp = median_fp_2s\n",
    "                        elif median_2s-median_1s == diff and last_fp > median_fp_2s:\n",
    "                            last = s2clf\n",
    "                            last_fp = median_fp_2s\n",
    "                    resultado[metric+'_Abs_Median'].append(diff)\n",
    "                    resultado[metric+\"_Rel_Median\"].append(np.nan)\n",
    "                else:\n",
    "                    abs = 0\n",
    "                    for s2clf in data['Classifier_2s'].unique():\n",
    "                        median_2s = data.query(\"Classifier_1s == '\"+s1clf+\"' and Classifier_2s == '\"+s2clf+\"'\")[metric].median()\n",
    "                        median_fp_2s = data.query(\"Classifier_1s == '\"+s1clf+\"' and Classifier_2s == '\"+s2clf+\"'\")['FP'].median()\n",
    "                        temp = (median_2s-median_1s)*100/median_1s\n",
    "                        if temp > diff:\n",
    "                            diff = temp\n",
    "                            abs = median_2s-median_1s\n",
    "                            last = s2clf\n",
    "                            last_fp = median_fp_2s\n",
    "                        elif temp == diff and last_fp > median_fp_2s:\n",
    "                            last = s2clf\n",
    "                            last_fp = median_fp_2s\n",
    "                    resultado[metric+'_Abs_Median'].append(abs)\n",
    "                    resultado[metric+\"_Rel_Median\"].append(diff)\n",
    "                median_2s = data.query(\"Classifier_1s == '\"+s1clf+\"' and Classifier_2s == '\"+last+\"'\")[metric].median()\n",
    "                median_fp_2s = data.query(\"Classifier_1s == '\"+s1clf+\"' and Classifier_2s == '\"+last+\"'\")['FP'].median()\n",
    "                median_fn_2s = data.query(\"Classifier_1s == '\"+s1clf+\"' and Classifier_2s == '\"+last+\"'\")['FN'].median()\n",
    "                \n",
    "                resultado['Classifier_2s_'+metric+'_Median'].append(last)\n",
    "                resultado[metric+\"_2s_Median\"].append(median_2s)\n",
    "                \n",
    "                resultado['FP_2s_Median_'+metric].append(median_fp_2s)\n",
    "                resultado['FN_2s_Median_'+metric].append(median_fn_2s)\n",
    "                resultado['FPR_2s_Median_'+metric].append(median_fp_2s/(int(test_size)-int(contamination)))\n",
    "                resultado['FNR_2s_Median_'+metric].append(median_fn_2s/int(contamination))\n",
    "                \n",
    "                diff = 0\n",
    "                last = \"1step_only\"\n",
    "                last_fp = 9999999\n",
    "                if mean_1s == 0.0:\n",
    "                    for s2clf in data['Classifier_2s'].unique():\n",
    "                        mean_2s = data.query(\"Classifier_1s == '\"+s1clf+\"' and Classifier_2s == '\"+s2clf+\"'\")[metric].mean()\n",
    "                        mean_fp_2s = data.query(\"Classifier_1s == '\"+s1clf+\"' and Classifier_2s == '\"+s2clf+\"'\")['FP'].mean()\n",
    "                        if mean_2s-mean_1s > diff:\n",
    "                            diff = mean_2s-mean_1s\n",
    "                            last = s2clf\n",
    "                            last_fp = mean_fp_2s\n",
    "                        elif mean_2s-mean_1s == diff and last_fp > mean_fp_2s:\n",
    "                            last = s2clf\n",
    "                            last_fp = mean_fp_2s\n",
    "                    resultado[metric+'_Abs_Mean'].append(diff)\n",
    "                    resultado[metric+\"_Rel_Mean\"].append(np.nan)\n",
    "                else:\n",
    "                    abs = 0\n",
    "                    for s2clf in data['Classifier_2s'].unique():\n",
    "                        mean_2s = data.query(\"Classifier_1s == '\"+s1clf+\"' and Classifier_2s == '\"+s2clf+\"'\")[metric].mean()\n",
    "                        mean_fp_2s = data.query(\"Classifier_1s == '\"+s1clf+\"' and Classifier_2s == '\"+s2clf+\"'\")['FP'].mean()\n",
    "                        temp = (mean_2s-mean_1s)*100/mean_1s\n",
    "                        if temp > diff:\n",
    "                            diff = temp\n",
    "                            abs = mean_2s-mean_1s\n",
    "                            last = s2clf\n",
    "                            last_fp = mean_fp_2s\n",
    "                        elif temp == diff and last_fp > mean_fp_2s:\n",
    "                            last = s2clf\n",
    "                            last_fp = mean_fp_2s\n",
    "                    resultado[metric+'_Abs_Mean'].append(abs)\n",
    "                    resultado[metric+\"_Rel_Mean\"].append(diff)\n",
    "                mean_2s = data.query(\"Classifier_1s == '\"+s1clf+\"' and Classifier_2s == '\"+last+\"'\")[metric].mean()\n",
    "                mean_fp_2s = data.query(\"Classifier_1s == '\"+s1clf+\"' and Classifier_2s == '\"+last+\"'\")['FP'].mean()\n",
    "                mean_fn_2s = data.query(\"Classifier_1s == '\"+s1clf+\"' and Classifier_2s == '\"+last+\"'\")['FN'].mean()\n",
    "                \n",
    "                resultado['Classifier_2s_'+metric+'_Mean'].append(last)\n",
    "                resultado[metric+\"_2s_Mean\"].append(mean_2s)\n",
    "                \n",
    "                resultado['FP_2s_Mean_'+metric].append(mean_fp_2s)\n",
    "                resultado['FN_2s_Mean_'+metric].append(mean_fn_2s)\n",
    "                resultado['FPR_2s_Mean_'+metric].append(mean_fp_2s/(int(test_size)-int(contamination)))\n",
    "                resultado['FNR_2s_Mean_'+metric].append(mean_fn_2s/int(contamination))\n",
    "toc = time()\n",
    "timer(toc-tic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2c249a",
   "metadata": {},
   "source": [
    "Salvando resultado em arquivo .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c81dceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(resultado).to_csv(\"Stats.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
